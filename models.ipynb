{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.88\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Bream       1.00      1.00      1.00        10\n",
      "      Parkki       1.00      1.00      1.00         1\n",
      "       Perch       0.69      1.00      0.82         9\n",
      "        Pike       1.00      1.00      1.00         3\n",
      "       Roach       0.00      0.00      0.00         1\n",
      "       Smelt       1.00      1.00      1.00         5\n",
      "   Whitefish       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.67      0.71      0.69        32\n",
      "weighted avg       0.79      0.88      0.82        32\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\sehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1471: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('fish.csv')\n",
    "\n",
    "X = data.drop(columns=['Species'])\n",
    "\n",
    "# Target variable ('Species')\n",
    "y = data['Species']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report_str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Accuracy**: The overall accuracy of the classification model is **0.88** (or 88%). This means that approximately 88% of the predictions made by the model are correct.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision measures the proportion of true positive predictions (correctly predicted instances) out of all positive predictions (both true positives and false positives).\n",
    "   - For each class (species):\n",
    "       - Bream: 100% precision (all predicted Bream instances are correct).\n",
    "       - Parkki: 100% precision.\n",
    "       - Perch: 69% precision (some false positives).\n",
    "       - Pike: 100% precision.\n",
    "       - Roach: 0% precision (all predicted Roach instances are incorrect).\n",
    "       - Smelt: 100% precision.\n",
    "       - Whitefish: 0% precision.\n",
    "   - Weighted average precision: 79%\n",
    "\n",
    "3. **Recall (Sensitivity)**:\n",
    "   - Recall measures the proportion of true positive predictions out of all actual positive instances.\n",
    "   - For each class:\n",
    "       - Bream: 100% recall (all actual Bream instances are correctly predicted).\n",
    "       - Parkki: 100% recall.\n",
    "       - Perch: 100% recall (no false negatives).\n",
    "       - Pike: 100% recall.\n",
    "       - Roach: 0% recall (all actual Roach instances are missed).\n",
    "       - Smelt: 100% recall.\n",
    "       - Whitefish: 0% recall (all actual Whitefish instances are missed).\n",
    "   - Weighted average recall: 88%\n",
    "\n",
    "4. **F1-Score**:\n",
    "   - The F1-score balances precision and recall, providing a single metric.\n",
    "   - It considers both false positives and false negatives.\n",
    "   - Weighted average F1-score: 82%\n",
    "\n",
    "5. **Support**:\n",
    "   - The number of instances (samples) for each class.\n",
    "   - For example, there are 10 instances of Bream, 1 instance of Parkki, and so on.\n",
    "\n",
    "6. **Macro Average**:\n",
    "   - The average precision, recall, and F1-score across all classes (unweighted).\n",
    "   - Macro average precision: 67%\n",
    "   - Macro average recall: 71%\n",
    "   - Macro average F1-score: 69%\n",
    "\n",
    "7. **Weighted Average**:\n",
    "   - The average precision, recall, and F1-score, weighted by the number of instances in each class.\n",
    "   - Weighted average precision: 79%\n",
    "   - Weighted average recall: 88%\n",
    "   - Weighted average F1-score: 82%\n",
    "\n",
    "In summary, the model performs well in some classes (e.g., Bream, Parkki, Pike, Smelt) but struggles with others (e.g., Roach, Whitefish). Improving precision and recall for the challenging classes would enhance overall model performance. üìäüêü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Bream       1.00      0.88      0.93        16\n",
      "      Parkki       0.71      1.00      0.83         5\n",
      "       Perch       1.00      0.29      0.45        17\n",
      "        Pike       1.00      1.00      1.00        10\n",
      "       Roach       0.44      0.80      0.57        10\n",
      "       Smelt       0.78      1.00      0.88         7\n",
      "   Whitefish       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.77        79\n",
      "   macro avg       0.81      0.83      0.78        79\n",
      "weighted avg       0.85      0.77      0.76        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE  # For addressing class imbalance\n",
    "\n",
    "# Features (excluding 'Species')\n",
    "X = data.drop(columns=['Species'])\n",
    "\n",
    "# Target variable ('Species')\n",
    "y = data['Species']\n",
    "\n",
    "# Address class imbalance using SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Accuracy (Overall Performance)**:\n",
    "   - The overall accuracy of the model is **0.77** (or 77%).\n",
    "   - This means that approximately 77% of the predictions made by the model are correct.\n",
    "\n",
    "2. **Precision**:\n",
    "   - Precision measures the proportion of true positive predictions (correctly predicted instances) out of all positive predictions (both true positives and false positives).\n",
    "   - For each class (species):\n",
    "       - Bream: 100% precision (all predicted Bream instances are correct).\n",
    "       - Parkki: 71% precision.\n",
    "       - Perch: 100% precision (some false positives).\n",
    "       - Pike: 100% precision.\n",
    "       - Roach: 44% precision (some false positives).\n",
    "       - Smelt: 78% precision.\n",
    "       - Whitefish: 75% precision.\n",
    "\n",
    "3. **Recall (Sensitivity)**:\n",
    "   - Recall measures the proportion of true positive predictions out of all actual positive instances.\n",
    "   - For each class:\n",
    "       - Bream: 88% recall (some actual Bream instances are missed).\n",
    "       - Parkki: 100% recall.\n",
    "       - Perch: 29% recall (many false negatives).\n",
    "       - Pike: 100% recall.\n",
    "       - Roach: 80% recall.\n",
    "       - Smelt: 100% recall.\n",
    "       - Whitefish: 86% recall.\n",
    "\n",
    "4. **F1-Score**:\n",
    "   - The F1-score balances precision and recall, providing a single metric.\n",
    "   - It considers both false positives and false negatives.\n",
    "   - Weighted average F1-score: 76%\n",
    "\n",
    "5. **Macro Average**:\n",
    "   - The average precision, recall, and F1-score across all classes (unweighted).\n",
    "   - Macro average precision: 81%\n",
    "   - Macro average recall: 83%\n",
    "   - Macro average F1-score: 78%\n",
    "\n",
    "6. **Weighted Average**:\n",
    "   - The average precision, recall, and F1-score, weighted by the number of instances in each class.\n",
    "   - Weighted average precision: 85%\n",
    "   - Weighted average recall: 77%\n",
    "   - Weighted average F1-score: 76%\n",
    "\n",
    "In summary, the model's performance has slightly decreased compared to the previous accuracy of 0.88. However, this makes the model more generalized. It still performs well for some classes but struggles with others. Improving recall for classes like Perch and Roach could enhance overall model effectiveness. üìäüêü"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the model to disk\n",
    "filename = './models/finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.77\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Bream       1.00      0.88      0.93        16\n",
      "      Parkki       0.71      1.00      0.83         5\n",
      "       Perch       1.00      0.29      0.45        17\n",
      "        Pike       1.00      1.00      1.00        10\n",
      "       Roach       0.44      0.80      0.57        10\n",
      "       Smelt       0.78      1.00      0.88         7\n",
      "   Whitefish       0.75      0.86      0.80        14\n",
      "\n",
      "    accuracy                           0.77        79\n",
      "   macro avg       0.81      0.83      0.78        79\n",
      "weighted avg       0.85      0.77      0.76        79\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "y_pred = loaded_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_report_str = classification_report(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weight</th>\n",
       "      <th>Length1</th>\n",
       "      <th>Length2</th>\n",
       "      <th>Length3</th>\n",
       "      <th>Height</th>\n",
       "      <th>Width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>78.000000</td>\n",
       "      <td>16.800000</td>\n",
       "      <td>18.700000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>5.199200</td>\n",
       "      <td>3.123400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>384.220176</td>\n",
       "      <td>29.182110</td>\n",
       "      <td>31.370550</td>\n",
       "      <td>34.664770</td>\n",
       "      <td>9.449847</td>\n",
       "      <td>5.305398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>553.915243</td>\n",
       "      <td>40.384355</td>\n",
       "      <td>43.302505</td>\n",
       "      <td>46.126706</td>\n",
       "      <td>7.779587</td>\n",
       "      <td>5.144507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>270.000000</td>\n",
       "      <td>23.600000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>28.700000</td>\n",
       "      <td>8.380400</td>\n",
       "      <td>4.247600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>785.753632</td>\n",
       "      <td>33.279212</td>\n",
       "      <td>35.891166</td>\n",
       "      <td>39.156375</td>\n",
       "      <td>11.187795</td>\n",
       "      <td>5.856610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>473.947581</td>\n",
       "      <td>27.301271</td>\n",
       "      <td>29.776807</td>\n",
       "      <td>32.703415</td>\n",
       "      <td>10.165772</td>\n",
       "      <td>5.995808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>110.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>5.692500</td>\n",
       "      <td>3.555000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>700.000000</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>39.400000</td>\n",
       "      <td>10.835000</td>\n",
       "      <td>6.264600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>363.000000</td>\n",
       "      <td>26.300000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>12.730000</td>\n",
       "      <td>4.455500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>610.000000</td>\n",
       "      <td>30.900000</td>\n",
       "      <td>33.500000</td>\n",
       "      <td>38.600000</td>\n",
       "      <td>15.633000</td>\n",
       "      <td>5.133800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>79 rows √ó 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Weight    Length1    Length2    Length3     Height     Width\n",
       "78    78.000000  16.800000  18.700000  19.400000   5.199200  3.123400\n",
       "274  384.220176  29.182110  31.370550  34.664770   9.449847  5.305398\n",
       "246  553.915243  40.384355  43.302505  46.126706   7.779587  5.144507\n",
       "55   270.000000  23.600000  26.000000  28.700000   8.380400  4.247600\n",
       "387  785.753632  33.279212  35.891166  39.156375  11.187795  5.856610\n",
       "..          ...        ...        ...        ...        ...       ...\n",
       "361  473.947581  27.301271  29.776807  32.703415  10.165772  5.995808\n",
       "82   110.000000  19.000000  21.000000  22.500000   5.692500  3.555000\n",
       "114  700.000000  34.500000  37.000000  39.400000  10.835000  6.264600\n",
       "3    363.000000  26.300000  29.000000  33.500000  12.730000  4.455500\n",
       "18   610.000000  30.900000  33.500000  38.600000  15.633000  5.133800\n",
       "\n",
       "[79 rows x 6 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_test_scaled = scaler.transform(X_test)\n",
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter the following features: Weight, Length1, Length2, Length3, Height, Width\n",
      "Predicted class: Roach\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sehre\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\base.py:465: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# User input\n",
    "print(\"Please enter the following features: Weight, Length1, Length2, Length3, Height, Width\")\n",
    "user_input = [float(x) for x in input().split()]\n",
    "\n",
    "# Convert user input into a numpy array and reshape it\n",
    "user_input = np.array(user_input).reshape(1, -1)\n",
    "\n",
    "# Standardize user input\n",
    "user_input_scaled = scaler.transform(user_input)\n",
    "\n",
    "# Use the loaded model to make predictions\n",
    "user_pred = loaded_model.predict(user_input_scaled)\n",
    "\n",
    "print(f\"Predicted class: {user_pred[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Bream       1.00      1.00      1.00        10\n",
      "      Parkki       1.00      1.00      1.00         1\n",
      "       Perch       0.69      1.00      0.82         9\n",
      "        Pike       1.00      1.00      1.00         3\n",
      "       Roach       0.00      0.00      0.00         1\n",
      "       Smelt       1.00      1.00      1.00         5\n",
      "   Whitefish       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.88        32\n",
      "   macro avg       0.67      0.71      0.69        32\n",
      "weighted avg       0.79      0.88      0.82        32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Features (excluding 'Species')\n",
    "X = data.drop(columns=['Species'])\n",
    "\n",
    "# Target variable ('Species')\n",
    "y = data['Species'].astype(str)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Train a logistic regression model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make probability predictions\n",
    "y_prob = model.predict_proba(X_test_scaled)\n",
    "\n",
    "threshold = 0.3\n",
    "y_pred = (y_prob[:, 2] > threshold) | (y_prob[:, 4] > threshold)  # Perch and Roach indices\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(\"Classification Report:\\n\", classification_report_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error: 83.71 grams\n"
     ]
    }
   ],
   "source": [
    "# Features (excluding 'Weight')\n",
    "X_reg = data.drop(columns=['Weight'])\n",
    "\n",
    "# Convert categorical variables into numerical form\n",
    "X_reg = pd.get_dummies(X_reg, columns=['Species'])\n",
    "\n",
    "# Target variable ('Weight')\n",
    "y_reg = data['Weight']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(X_reg, y_reg, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model\n",
    "reg_model = LinearRegression()\n",
    "reg_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Make weight predictions\n",
    "y_pred_reg = reg_model.predict(X_test_reg)\n",
    "\n",
    "# Evaluate model performance (Root Mean Squared Error)\n",
    "rmse = mean_squared_error(y_test_reg, y_pred_reg, squared=False)\n",
    "\n",
    "print(f\"Root Mean Squared Error: {rmse:.2f} grams\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
